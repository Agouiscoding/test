{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f66b5bb1-381a-4655-8177-9a033275c55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/200] [Batch 1/938] [D loss: 1.3979] [G loss: 0.6856]\n",
      "[Epoch 1/200] [Batch 2/938] [D loss: 1.3150] [G loss: 0.6565]\n",
      "[Epoch 1/200] [Batch 3/938] [D loss: 1.2704] [G loss: 0.6287]\n",
      "[Epoch 1/200] [Batch 4/938] [D loss: 1.2494] [G loss: 0.6029]\n",
      "[Epoch 1/200] [Batch 5/938] [D loss: 1.2614] [G loss: 0.5796]\n",
      "[Epoch 1/200] [Batch 6/938] [D loss: 1.2823] [G loss: 0.5604]\n",
      "[Epoch 1/200] [Batch 7/938] [D loss: 1.3079] [G loss: 0.5489]\n",
      "[Epoch 1/200] [Batch 8/938] [D loss: 1.3305] [G loss: 0.5428]\n",
      "[Epoch 1/200] [Batch 9/938] [D loss: 1.3385] [G loss: 0.5463]\n",
      "[Epoch 1/200] [Batch 10/938] [D loss: 1.3278] [G loss: 0.5593]\n",
      "[Epoch 1/200] [Batch 11/938] [D loss: 1.3088] [G loss: 0.5798]\n",
      "[Epoch 1/200] [Batch 12/938] [D loss: 1.2753] [G loss: 0.6119]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/200] [Batch 13/938] [D loss: 1.2284] [G loss: 0.6552]\n",
      "[Epoch 1/200] [Batch 14/938] [D loss: 1.1724] [G loss: 0.7107]\n",
      "[Epoch 1/200] [Batch 15/938] [D loss: 1.1330] [G loss: 0.7760]\n",
      "[Epoch 1/200] [Batch 16/938] [D loss: 1.0930] [G loss: 0.8521]\n",
      "[Epoch 1/200] [Batch 17/938] [D loss: 1.0601] [G loss: 0.9280]\n",
      "[Epoch 1/200] [Batch 18/938] [D loss: 1.0403] [G loss: 0.9968]\n",
      "[Epoch 1/200] [Batch 19/938] [D loss: 1.0239] [G loss: 1.0473]\n",
      "[Epoch 1/200] [Batch 20/938] [D loss: 1.0177] [G loss: 1.0653]\n",
      "[Epoch 1/200] [Batch 21/938] [D loss: 1.0319] [G loss: 1.0461]\n",
      "[Epoch 1/200] [Batch 22/938] [D loss: 1.0340] [G loss: 1.0011]\n",
      "[Epoch 1/200] [Batch 23/938] [D loss: 1.0709] [G loss: 0.9365]\n",
      "[Epoch 1/200] [Batch 24/938] [D loss: 1.1189] [G loss: 0.8726]\n",
      "[Epoch 1/200] [Batch 25/938] [D loss: 1.1534] [G loss: 0.8336]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/200] [Batch 26/938] [D loss: 1.2191] [G loss: 0.8042]\n",
      "[Epoch 1/200] [Batch 27/938] [D loss: 1.2753] [G loss: 0.7948]\n",
      "[Epoch 1/200] [Batch 28/938] [D loss: 1.3153] [G loss: 0.7897]\n",
      "[Epoch 1/200] [Batch 29/938] [D loss: 1.3751] [G loss: 0.7908]\n",
      "[Epoch 1/200] [Batch 30/938] [D loss: 1.4042] [G loss: 0.7998]\n",
      "[Epoch 1/200] [Batch 31/938] [D loss: 1.4307] [G loss: 0.8045]\n",
      "[Epoch 1/200] [Batch 32/938] [D loss: 1.4103] [G loss: 0.8143]\n",
      "[Epoch 1/200] [Batch 33/938] [D loss: 1.3879] [G loss: 0.8309]\n",
      "[Epoch 1/200] [Batch 34/938] [D loss: 1.3229] [G loss: 0.8608]\n",
      "[Epoch 1/200] [Batch 35/938] [D loss: 1.2573] [G loss: 0.9146]\n",
      "[Epoch 1/200] [Batch 36/938] [D loss: 1.1857] [G loss: 0.9842]\n",
      "[Epoch 1/200] [Batch 37/938] [D loss: 1.0819] [G loss: 1.0864]\n",
      "[Epoch 1/200] [Batch 38/938] [D loss: 1.0195] [G loss: 1.1962]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/200] [Batch 39/938] [D loss: 0.9310] [G loss: 1.3239]\n",
      "[Epoch 1/200] [Batch 40/938] [D loss: 0.8367] [G loss: 1.4639]\n",
      "[Epoch 1/200] [Batch 41/938] [D loss: 0.7757] [G loss: 1.6152]\n",
      "[Epoch 1/200] [Batch 42/938] [D loss: 0.6966] [G loss: 1.7673]\n",
      "[Epoch 1/200] [Batch 43/938] [D loss: 0.6568] [G loss: 1.9010]\n",
      "[Epoch 1/200] [Batch 44/938] [D loss: 0.5942] [G loss: 2.0558]\n",
      "[Epoch 1/200] [Batch 45/938] [D loss: 0.5636] [G loss: 2.1710]\n",
      "[Epoch 1/200] [Batch 46/938] [D loss: 0.5357] [G loss: 2.2969]\n",
      "[Epoch 1/200] [Batch 47/938] [D loss: 0.5155] [G loss: 2.4160]\n",
      "[Epoch 1/200] [Batch 48/938] [D loss: 0.5039] [G loss: 2.4388]\n",
      "[Epoch 1/200] [Batch 49/938] [D loss: 0.5015] [G loss: 2.5560]\n",
      "[Epoch 1/200] [Batch 50/938] [D loss: 0.4903] [G loss: 2.6207]\n",
      "[Epoch 1/200] [Batch 51/938] [D loss: 0.4834] [G loss: 2.7083]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|          | 0/200 [00:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/200] [Batch 52/938] [D loss: 0.4811] [G loss: 2.7260]\n",
      "[Epoch 1/200] [Batch 53/938] [D loss: 0.4992] [G loss: 2.7248]\n",
      "[Epoch 1/200] [Batch 54/938] [D loss: 0.5172] [G loss: 2.7704]\n",
      "[Epoch 1/200] [Batch 55/938] [D loss: 0.5394] [G loss: 2.7499]\n",
      "[Epoch 1/200] [Batch 56/938] [D loss: 0.5760] [G loss: 2.7426]\n",
      "[Epoch 1/200] [Batch 57/938] [D loss: 0.5676] [G loss: 2.7833]\n",
      "[Epoch 1/200] [Batch 58/938] [D loss: 0.6546] [G loss: 2.7310]\n",
      "[Epoch 1/200] [Batch 59/938] [D loss: 0.6536] [G loss: 2.7590]\n",
      "[Epoch 1/200] [Batch 60/938] [D loss: 0.6817] [G loss: 2.6706]\n",
      "[Epoch 1/200] [Batch 61/938] [D loss: 0.7023] [G loss: 2.6035]\n",
      "[Epoch 1/200] [Batch 62/938] [D loss: 0.7176] [G loss: 2.7075]\n",
      "[Epoch 1/200] [Batch 63/938] [D loss: 0.7458] [G loss: 2.7399]\n",
      "[Epoch 1/200] [Batch 64/938] [D loss: 0.7315] [G loss: 2.6070]\n",
      "[Epoch 1/200] [Batch 65/938] [D loss: 0.8331] [G loss: 2.5665]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|          | 0/200 [00:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/200] [Batch 66/938] [D loss: 0.7398] [G loss: 2.8167]\n",
      "[Epoch 1/200] [Batch 67/938] [D loss: 0.7060] [G loss: 2.9657]\n",
      "[Epoch 1/200] [Batch 68/938] [D loss: 0.6945] [G loss: 2.9930]\n",
      "[Epoch 1/200] [Batch 69/938] [D loss: 0.6778] [G loss: 3.1420]\n",
      "[Epoch 1/200] [Batch 70/938] [D loss: 0.7242] [G loss: 2.9316]\n",
      "[Epoch 1/200] [Batch 71/938] [D loss: 0.7479] [G loss: 2.9748]\n",
      "[Epoch 1/200] [Batch 72/938] [D loss: 0.7583] [G loss: 3.2384]\n",
      "[Epoch 1/200] [Batch 73/938] [D loss: 0.7036] [G loss: 3.4072]\n",
      "[Epoch 1/200] [Batch 74/938] [D loss: 0.7372] [G loss: 3.4311]\n",
      "[Epoch 1/200] [Batch 75/938] [D loss: 0.7927] [G loss: 3.4328]\n",
      "[Epoch 1/200] [Batch 76/938] [D loss: 0.8062] [G loss: 3.4689]\n",
      "[Epoch 1/200] [Batch 77/938] [D loss: 0.8806] [G loss: 3.0657]\n",
      "[Epoch 1/200] [Batch 78/938] [D loss: 0.9115] [G loss: 3.3360]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|          | 0/200 [00:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/200] [Batch 79/938] [D loss: 0.8487] [G loss: 3.6800]\n",
      "[Epoch 1/200] [Batch 80/938] [D loss: 0.8461] [G loss: 3.5155]\n",
      "[Epoch 1/200] [Batch 81/938] [D loss: 0.8709] [G loss: 3.4014]\n",
      "[Epoch 1/200] [Batch 82/938] [D loss: 0.9200] [G loss: 3.1840]\n",
      "[Epoch 1/200] [Batch 83/938] [D loss: 0.8483] [G loss: 3.6777]\n",
      "[Epoch 1/200] [Batch 84/938] [D loss: 0.8017] [G loss: 3.2458]\n",
      "[Epoch 1/200] [Batch 85/938] [D loss: 0.7250] [G loss: 4.0056]\n",
      "[Epoch 1/200] [Batch 86/938] [D loss: 0.6783] [G loss: 3.9560]\n",
      "[Epoch 1/200] [Batch 87/938] [D loss: 0.6380] [G loss: 4.2745]\n",
      "[Epoch 1/200] [Batch 88/938] [D loss: 0.6245] [G loss: 3.9447]\n",
      "[Epoch 1/200] [Batch 89/938] [D loss: 0.6135] [G loss: 3.9447]\n",
      "[Epoch 1/200] [Batch 90/938] [D loss: 0.5472] [G loss: 4.5484]\n",
      "[Epoch 1/200] [Batch 91/938] [D loss: 0.5349] [G loss: 4.8329]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|          | 0/200 [00:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/200] [Batch 92/938] [D loss: 0.5311] [G loss: 4.8793]\n",
      "[Epoch 1/200] [Batch 93/938] [D loss: 0.5002] [G loss: 5.4593]\n",
      "[Epoch 1/200] [Batch 94/938] [D loss: 0.5392] [G loss: 5.3062]\n",
      "[Epoch 1/200] [Batch 95/938] [D loss: 0.4920] [G loss: 5.5157]\n",
      "[Epoch 1/200] [Batch 96/938] [D loss: 0.4770] [G loss: 6.1889]\n",
      "[Epoch 1/200] [Batch 97/938] [D loss: 0.4930] [G loss: 5.1938]\n",
      "[Epoch 1/200] [Batch 98/938] [D loss: 0.4801] [G loss: 5.5114]\n",
      "[Epoch 1/200] [Batch 99/938] [D loss: 0.5389] [G loss: 4.6330]\n",
      "[Epoch 1/200] [Batch 100/938] [D loss: 0.5228] [G loss: 5.3698]\n",
      "[Epoch 1/200] [Batch 101/938] [D loss: 0.5416] [G loss: 5.2732]\n",
      "[Epoch 1/200] [Batch 102/938] [D loss: 0.5615] [G loss: 4.8635]\n",
      "[Epoch 1/200] [Batch 103/938] [D loss: 0.5468] [G loss: 5.9088]\n",
      "[Epoch 1/200] [Batch 104/938] [D loss: 0.6089] [G loss: 4.8789]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|          | 0/200 [00:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/200] [Batch 105/938] [D loss: 0.6465] [G loss: 4.8428]\n",
      "[Epoch 1/200] [Batch 106/938] [D loss: 0.6571] [G loss: 5.2164]\n",
      "[Epoch 1/200] [Batch 107/938] [D loss: 0.6979] [G loss: 5.4814]\n",
      "[Epoch 1/200] [Batch 108/938] [D loss: 0.7309] [G loss: 5.4732]\n",
      "[Epoch 1/200] [Batch 109/938] [D loss: 0.7776] [G loss: 4.4104]\n",
      "[Epoch 1/200] [Batch 110/938] [D loss: 0.7774] [G loss: 5.2663]\n",
      "[Epoch 1/200] [Batch 111/938] [D loss: 0.8222] [G loss: 4.2189]\n",
      "[Epoch 1/200] [Batch 112/938] [D loss: 0.7715] [G loss: 4.5954]\n",
      "[Epoch 1/200] [Batch 113/938] [D loss: 0.7593] [G loss: 4.4541]\n",
      "[Epoch 1/200] [Batch 114/938] [D loss: 0.7473] [G loss: 5.0773]\n",
      "[Epoch 1/200] [Batch 115/938] [D loss: 0.7142] [G loss: 4.3334]\n",
      "[Epoch 1/200] [Batch 116/938] [D loss: 0.6902] [G loss: 4.1910]\n",
      "[Epoch 1/200] [Batch 117/938] [D loss: 0.6618] [G loss: 4.2638]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|          | 0/200 [00:02<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/200] [Batch 118/938] [D loss: 0.6200] [G loss: 4.8397]\n",
      "[Epoch 1/200] [Batch 119/938] [D loss: 0.6142] [G loss: 3.9331]\n",
      "[Epoch 1/200] [Batch 120/938] [D loss: 0.6131] [G loss: 3.8187]\n",
      "[Epoch 1/200] [Batch 121/938] [D loss: 0.5569] [G loss: 4.1356]\n",
      "[Epoch 1/200] [Batch 122/938] [D loss: 0.5616] [G loss: 3.9042]\n",
      "[Epoch 1/200] [Batch 123/938] [D loss: 0.5469] [G loss: 3.8380]\n",
      "[Epoch 1/200] [Batch 124/938] [D loss: 0.5313] [G loss: 4.1411]\n",
      "[Epoch 1/200] [Batch 125/938] [D loss: 0.5426] [G loss: 3.8761]\n",
      "[Epoch 1/200] [Batch 126/938] [D loss: 0.5782] [G loss: 3.4461]\n",
      "[Epoch 1/200] [Batch 127/938] [D loss: 0.5403] [G loss: 4.2242]\n",
      "[Epoch 1/200] [Batch 128/938] [D loss: 0.5842] [G loss: 3.8034]\n",
      "[Epoch 1/200] [Batch 129/938] [D loss: 0.6311] [G loss: 3.7131]\n",
      "[Epoch 1/200] [Batch 130/938] [D loss: 0.6135] [G loss: 4.1226]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|          | 0/200 [00:02<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/200] [Batch 131/938] [D loss: 0.7107] [G loss: 3.7141]\n",
      "[Epoch 1/200] [Batch 132/938] [D loss: 0.7346] [G loss: 4.0977]\n",
      "[Epoch 1/200] [Batch 133/938] [D loss: 0.8121] [G loss: 3.4122]\n",
      "[Epoch 1/200] [Batch 134/938] [D loss: 0.8810] [G loss: 3.5137]\n",
      "[Epoch 1/200] [Batch 135/938] [D loss: 0.8932] [G loss: 3.6252]\n",
      "[Epoch 1/200] [Batch 136/938] [D loss: 0.9330] [G loss: 3.6189]\n",
      "[Epoch 1/200] [Batch 137/938] [D loss: 0.9485] [G loss: 4.3103]\n",
      "[Epoch 1/200] [Batch 138/938] [D loss: 0.9899] [G loss: 4.0630]\n",
      "[Epoch 1/200] [Batch 139/938] [D loss: 0.9586] [G loss: 4.2970]\n",
      "[Epoch 1/200] [Batch 140/938] [D loss: 0.9080] [G loss: 4.8675]\n",
      "[Epoch 1/200] [Batch 141/938] [D loss: 0.8822] [G loss: 4.2099]\n",
      "[Epoch 1/200] [Batch 142/938] [D loss: 0.7590] [G loss: 5.1315]\n",
      "[Epoch 1/200] [Batch 143/938] [D loss: 0.7299] [G loss: 5.0418]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|          | 0/200 [00:02<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/200] [Batch 144/938] [D loss: 0.7399] [G loss: 5.1522]\n",
      "[Epoch 1/200] [Batch 145/938] [D loss: 0.7033] [G loss: 4.8122]\n",
      "[Epoch 1/200] [Batch 146/938] [D loss: 0.6152] [G loss: 4.7952]\n",
      "[Epoch 1/200] [Batch 147/938] [D loss: 0.6139] [G loss: 4.9466]\n",
      "[Epoch 1/200] [Batch 148/938] [D loss: 0.5290] [G loss: 6.3082]\n",
      "[Epoch 1/200] [Batch 149/938] [D loss: 0.5370] [G loss: 5.5709]\n",
      "[Epoch 1/200] [Batch 150/938] [D loss: 0.5039] [G loss: 5.4940]\n",
      "[Epoch 1/200] [Batch 151/938] [D loss: 0.5077] [G loss: 5.4895]\n",
      "[Epoch 1/200] [Batch 152/938] [D loss: 0.4677] [G loss: 6.2470]\n",
      "[Epoch 1/200] [Batch 153/938] [D loss: 0.4819] [G loss: 6.0498]\n",
      "[Epoch 1/200] [Batch 154/938] [D loss: 0.4671] [G loss: 5.8026]\n",
      "[Epoch 1/200] [Batch 155/938] [D loss: 0.4882] [G loss: 5.1345]\n",
      "[Epoch 1/200] [Batch 156/938] [D loss: 0.5002] [G loss: 5.1430]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|          | 0/200 [00:02<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/200] [Batch 157/938] [D loss: 0.4799] [G loss: 5.4432]\n",
      "[Epoch 1/200] [Batch 158/938] [D loss: 0.4574] [G loss: 5.5716]\n",
      "[Epoch 1/200] [Batch 159/938] [D loss: 0.4628] [G loss: 5.0559]\n",
      "[Epoch 1/200] [Batch 160/938] [D loss: 0.4545] [G loss: 5.1715]\n",
      "[Epoch 1/200] [Batch 161/938] [D loss: 0.4771] [G loss: 4.3630]\n",
      "[Epoch 1/200] [Batch 162/938] [D loss: 0.4343] [G loss: 5.3007]\n",
      "[Epoch 1/200] [Batch 163/938] [D loss: 0.4697] [G loss: 4.7526]\n",
      "[Epoch 1/200] [Batch 164/938] [D loss: 0.4353] [G loss: 4.9842]\n",
      "[Epoch 1/200] [Batch 165/938] [D loss: 0.4712] [G loss: 4.5691]\n",
      "[Epoch 1/200] [Batch 166/938] [D loss: 0.4652] [G loss: 4.0989]\n",
      "[Epoch 1/200] [Batch 167/938] [D loss: 0.4428] [G loss: 4.7528]\n",
      "[Epoch 1/200] [Batch 168/938] [D loss: 0.4493] [G loss: 4.8462]\n",
      "[Epoch 1/200] [Batch 169/938] [D loss: 0.4529] [G loss: 4.5375]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|          | 0/200 [00:02<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/200] [Batch 170/938] [D loss: 0.4551] [G loss: 4.0507]\n",
      "[Epoch 1/200] [Batch 171/938] [D loss: 0.4604] [G loss: 3.8575]\n",
      "[Epoch 1/200] [Batch 172/938] [D loss: 0.4626] [G loss: 3.8663]\n",
      "[Epoch 1/200] [Batch 173/938] [D loss: 0.4403] [G loss: 4.0972]\n",
      "[Epoch 1/200] [Batch 174/938] [D loss: 0.4140] [G loss: 4.2657]\n",
      "[Epoch 1/200] [Batch 175/938] [D loss: 0.4261] [G loss: 3.9181]\n",
      "[Epoch 1/200] [Batch 176/938] [D loss: 0.4247] [G loss: 3.8364]\n",
      "[Epoch 1/200] [Batch 177/938] [D loss: 0.4092] [G loss: 4.0126]\n",
      "[Epoch 1/200] [Batch 178/938] [D loss: 0.4342] [G loss: 3.3730]\n",
      "[Epoch 1/200] [Batch 179/938] [D loss: 0.4314] [G loss: 3.5987]\n",
      "[Epoch 1/200] [Batch 180/938] [D loss: 0.4395] [G loss: 3.3218]\n",
      "[Epoch 1/200] [Batch 181/938] [D loss: 0.4423] [G loss: 3.4812]\n",
      "[Epoch 1/200] [Batch 182/938] [D loss: 0.4405] [G loss: 3.5250]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|          | 0/200 [00:03<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/200] [Batch 183/938] [D loss: 0.4650] [G loss: 3.3436]\n",
      "[Epoch 1/200] [Batch 184/938] [D loss: 0.4866] [G loss: 3.4110]\n",
      "[Epoch 1/200] [Batch 185/938] [D loss: 0.4690] [G loss: 3.2312]\n",
      "[Epoch 1/200] [Batch 186/938] [D loss: 0.4832] [G loss: 3.2983]\n",
      "[Epoch 1/200] [Batch 187/938] [D loss: 0.5119] [G loss: 3.1539]\n",
      "[Epoch 1/200] [Batch 188/938] [D loss: 0.5070] [G loss: 3.1946]\n",
      "[Epoch 1/200] [Batch 189/938] [D loss: 0.4710] [G loss: 3.5262]\n",
      "[Epoch 1/200] [Batch 190/938] [D loss: 0.4544] [G loss: 3.5836]\n",
      "[Epoch 1/200] [Batch 191/938] [D loss: 0.4726] [G loss: 3.7155]\n",
      "[Epoch 1/200] [Batch 192/938] [D loss: 0.4524] [G loss: 3.6748]\n",
      "[Epoch 1/200] [Batch 193/938] [D loss: 0.4427] [G loss: 3.6697]\n",
      "[Epoch 1/200] [Batch 194/938] [D loss: 0.4273] [G loss: 3.7741]\n",
      "[Epoch 1/200] [Batch 195/938] [D loss: 0.4153] [G loss: 4.1212]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/200] [Batch 196/938] [D loss: 0.4236] [G loss: 4.0221]\n",
      "[Epoch 1/200] [Batch 197/938] [D loss: 0.4335] [G loss: 4.0722]\n",
      "[Epoch 1/200] [Batch 198/938] [D loss: 0.4356] [G loss: 4.0435]\n",
      "[Epoch 1/200] [Batch 199/938] [D loss: 0.4153] [G loss: 4.1655]\n",
      "[Epoch 1/200] [Batch 200/938] [D loss: 0.4221] [G loss: 4.0678]\n",
      "[Epoch 1/200] [Batch 201/938] [D loss: 0.4325] [G loss: 4.1516]\n",
      "[Epoch 1/200] [Batch 202/938] [D loss: 0.4146] [G loss: 4.0482]\n",
      "[Epoch 1/200] [Batch 203/938] [D loss: 0.4040] [G loss: 4.3008]\n",
      "[Epoch 1/200] [Batch 204/938] [D loss: 0.3974] [G loss: 4.2330]\n",
      "[Epoch 1/200] [Batch 205/938] [D loss: 0.4205] [G loss: 4.4005]\n",
      "[Epoch 1/200] [Batch 206/938] [D loss: 0.4044] [G loss: 4.1275]\n",
      "[Epoch 1/200] [Batch 207/938] [D loss: 0.3962] [G loss: 4.2426]\n",
      "[Epoch 1/200] [Batch 208/938] [D loss: 0.4127] [G loss: 3.9763]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|          | 0/200 [00:03<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/200] [Batch 209/938] [D loss: 0.3972] [G loss: 4.3120]\n",
      "[Epoch 1/200] [Batch 210/938] [D loss: 0.4137] [G loss: 4.2220]\n",
      "[Epoch 1/200] [Batch 211/938] [D loss: 0.4016] [G loss: 4.1319]\n",
      "[Epoch 1/200] [Batch 212/938] [D loss: 0.3879] [G loss: 4.4462]\n",
      "[Epoch 1/200] [Batch 213/938] [D loss: 0.4021] [G loss: 4.4679]\n",
      "[Epoch 1/200] [Batch 214/938] [D loss: 0.3937] [G loss: 4.2644]\n",
      "[Epoch 1/200] [Batch 215/938] [D loss: 0.3951] [G loss: 4.4874]\n",
      "[Epoch 1/200] [Batch 216/938] [D loss: 0.4129] [G loss: 4.3512]\n",
      "[Epoch 1/200] [Batch 217/938] [D loss: 0.4186] [G loss: 4.1265]\n",
      "[Epoch 1/200] [Batch 218/938] [D loss: 0.4101] [G loss: 4.2659]\n",
      "[Epoch 1/200] [Batch 219/938] [D loss: 0.3868] [G loss: 4.8855]\n",
      "[Epoch 1/200] [Batch 220/938] [D loss: 0.4054] [G loss: 4.4783]\n",
      "[Epoch 1/200] [Batch 221/938] [D loss: 0.4281] [G loss: 4.3176]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|          | 0/200 [00:03<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/200] [Batch 222/938] [D loss: 0.3891] [G loss: 4.8201]\n",
      "[Epoch 1/200] [Batch 223/938] [D loss: 0.3806] [G loss: 4.8891]\n",
      "[Epoch 1/200] [Batch 224/938] [D loss: 0.4673] [G loss: 4.3726]\n",
      "[Epoch 1/200] [Batch 225/938] [D loss: 0.4510] [G loss: 4.3440]\n",
      "[Epoch 1/200] [Batch 226/938] [D loss: 0.4109] [G loss: 5.0423]\n",
      "[Epoch 1/200] [Batch 227/938] [D loss: 0.4278] [G loss: 5.0172]\n",
      "[Epoch 1/200] [Batch 228/938] [D loss: 0.4480] [G loss: 5.1162]\n",
      "[Epoch 1/200] [Batch 229/938] [D loss: 0.4008] [G loss: 5.7407]\n",
      "[Epoch 1/200] [Batch 230/938] [D loss: 0.3893] [G loss: 5.8725]\n",
      "[Epoch 1/200] [Batch 231/938] [D loss: 0.3895] [G loss: 5.7559]\n",
      "[Epoch 1/200] [Batch 232/938] [D loss: 0.3875] [G loss: 5.6914]\n",
      "[Epoch 1/200] [Batch 233/938] [D loss: 0.3929] [G loss: 6.2553]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|          | 0/200 [00:04<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/200] [Batch 234/938] [D loss: 0.3879] [G loss: 6.4620]\n",
      "[Epoch 1/200] [Batch 235/938] [D loss: 0.3787] [G loss: 5.8226]\n",
      "[Epoch 1/200] [Batch 236/938] [D loss: 0.3818] [G loss: 5.8221]\n",
      "[Epoch 1/200] [Batch 237/938] [D loss: 0.3950] [G loss: 5.9356]\n",
      "[Epoch 1/200] [Batch 238/938] [D loss: 0.3810] [G loss: 5.5796]\n",
      "[Epoch 1/200] [Batch 239/938] [D loss: 0.3966] [G loss: 5.1799]\n",
      "[Epoch 1/200] [Batch 240/938] [D loss: 0.3689] [G loss: 5.3544]\n",
      "[Epoch 1/200] [Batch 241/938] [D loss: 0.3696] [G loss: 5.3982]\n",
      "[Epoch 1/200] [Batch 242/938] [D loss: 0.3591] [G loss: 5.3672]\n",
      "[Epoch 1/200] [Batch 243/938] [D loss: 0.3591] [G loss: 5.3682]\n",
      "[Epoch 1/200] [Batch 244/938] [D loss: 0.3619] [G loss: 5.2566]\n",
      "[Epoch 1/200] [Batch 245/938] [D loss: 0.3629] [G loss: 5.0641]\n",
      "[Epoch 1/200] [Batch 246/938] [D loss: 0.3638] [G loss: 4.7938]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|          | 0/200 [00:04<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/200] [Batch 247/938] [D loss: 0.3571] [G loss: 4.6674]\n",
      "[Epoch 1/200] [Batch 248/938] [D loss: 0.3604] [G loss: 4.5976]\n",
      "[Epoch 1/200] [Batch 249/938] [D loss: 0.3614] [G loss: 4.4424]\n",
      "[Epoch 1/200] [Batch 250/938] [D loss: 0.3622] [G loss: 4.4749]\n",
      "[Epoch 1/200] [Batch 251/938] [D loss: 0.3639] [G loss: 4.4997]\n",
      "[Epoch 1/200] [Batch 252/938] [D loss: 0.3607] [G loss: 4.3564]\n",
      "[Epoch 1/200] [Batch 253/938] [D loss: 0.3653] [G loss: 4.3994]\n",
      "[Epoch 1/200] [Batch 254/938] [D loss: 0.3649] [G loss: 4.2520]\n",
      "[Epoch 1/200] [Batch 255/938] [D loss: 0.3856] [G loss: 3.9051]\n",
      "[Epoch 1/200] [Batch 256/938] [D loss: 0.3747] [G loss: 4.2840]\n",
      "[Epoch 1/200] [Batch 257/938] [D loss: 0.4111] [G loss: 4.2110]\n",
      "[Epoch 1/200] [Batch 258/938] [D loss: 0.4569] [G loss: 4.0733]\n",
      "[Epoch 1/200] [Batch 259/938] [D loss: 0.4751] [G loss: 4.1509]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|          | 0/200 [00:04<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/200] [Batch 260/938] [D loss: 0.5054] [G loss: 4.1823]\n",
      "[Epoch 1/200] [Batch 261/938] [D loss: 0.4707] [G loss: 4.3773]\n",
      "[Epoch 1/200] [Batch 262/938] [D loss: 0.4779] [G loss: 4.3642]\n",
      "[Epoch 1/200] [Batch 263/938] [D loss: 0.4796] [G loss: 4.3748]\n",
      "[Epoch 1/200] [Batch 264/938] [D loss: 0.4423] [G loss: 4.4765]\n",
      "[Epoch 1/200] [Batch 265/938] [D loss: 0.4338] [G loss: 4.6931]\n",
      "[Epoch 1/200] [Batch 266/938] [D loss: 0.4020] [G loss: 4.6417]\n",
      "[Epoch 1/200] [Batch 267/938] [D loss: 0.4078] [G loss: 4.4271]\n",
      "[Epoch 1/200] [Batch 268/938] [D loss: 0.3902] [G loss: 4.4253]\n",
      "[Epoch 1/200] [Batch 269/938] [D loss: 0.3738] [G loss: 4.4913]\n",
      "[Epoch 1/200] [Batch 270/938] [D loss: 0.3679] [G loss: 4.5056]\n",
      "[Epoch 1/200] [Batch 271/938] [D loss: 0.3752] [G loss: 4.2283]\n",
      "[Epoch 1/200] [Batch 272/938] [D loss: 0.3672] [G loss: 4.2659]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|          | 0/200 [00:04<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/200] [Batch 273/938] [D loss: 0.3745] [G loss: 3.9073]\n",
      "[Epoch 1/200] [Batch 274/938] [D loss: 0.3841] [G loss: 3.8959]\n",
      "[Epoch 1/200] [Batch 275/938] [D loss: 0.3862] [G loss: 3.8872]\n",
      "[Epoch 1/200] [Batch 276/938] [D loss: 0.3873] [G loss: 3.7258]\n",
      "[Epoch 1/200] [Batch 277/938] [D loss: 0.3938] [G loss: 3.4806]\n",
      "[Epoch 1/200] [Batch 278/938] [D loss: 0.3975] [G loss: 3.3389]\n",
      "[Epoch 1/200] [Batch 279/938] [D loss: 0.3899] [G loss: 3.5306]\n",
      "[Epoch 1/200] [Batch 280/938] [D loss: 0.4056] [G loss: 3.5273]\n",
      "[Epoch 1/200] [Batch 281/938] [D loss: 0.4131] [G loss: 3.5585]\n",
      "[Epoch 1/200] [Batch 282/938] [D loss: 0.3865] [G loss: 3.5443]\n",
      "[Epoch 1/200] [Batch 283/938] [D loss: 0.3910] [G loss: 3.5410]\n",
      "[Epoch 1/200] [Batch 284/938] [D loss: 0.3873] [G loss: 3.7045]\n",
      "[Epoch 1/200] [Batch 285/938] [D loss: 0.3879] [G loss: 3.7628]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|          | 0/200 [00:04<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/200] [Batch 286/938] [D loss: 0.3887] [G loss: 3.9577]\n",
      "[Epoch 1/200] [Batch 287/938] [D loss: 0.3833] [G loss: 3.9341]\n",
      "[Epoch 1/200] [Batch 288/938] [D loss: 0.3809] [G loss: 3.8678]\n",
      "[Epoch 1/200] [Batch 289/938] [D loss: 0.3768] [G loss: 4.0394]\n",
      "[Epoch 1/200] [Batch 290/938] [D loss: 0.3788] [G loss: 4.1203]\n",
      "[Epoch 1/200] [Batch 291/938] [D loss: 0.3849] [G loss: 4.0068]\n",
      "[Epoch 1/200] [Batch 292/938] [D loss: 0.3840] [G loss: 4.1912]\n",
      "[Epoch 1/200] [Batch 293/938] [D loss: 0.3922] [G loss: 4.1524]\n",
      "[Epoch 1/200] [Batch 294/938] [D loss: 0.3978] [G loss: 4.1493]\n",
      "[Epoch 1/200] [Batch 295/938] [D loss: 0.4101] [G loss: 4.2363]\n",
      "[Epoch 1/200] [Batch 296/938] [D loss: 0.4071] [G loss: 4.5396]\n",
      "[Epoch 1/200] [Batch 297/938] [D loss: 0.4311] [G loss: 4.4233]\n",
      "[Epoch 1/200] [Batch 298/938] [D loss: 0.4245] [G loss: 4.7477]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|          | 0/200 [00:05<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/200] [Batch 299/938] [D loss: 0.4374] [G loss: 4.2996]\n",
      "[Epoch 1/200] [Batch 300/938] [D loss: 0.4178] [G loss: 4.8563]\n",
      "[Epoch 1/200] [Batch 301/938] [D loss: 0.4126] [G loss: 5.0964]\n",
      "[Epoch 1/200] [Batch 302/938] [D loss: 0.4019] [G loss: 5.0259]\n",
      "[Epoch 1/200] [Batch 303/938] [D loss: 0.3858] [G loss: 5.4252]\n",
      "[Epoch 1/200] [Batch 304/938] [D loss: 0.4107] [G loss: 5.8011]\n",
      "[Epoch 1/200] [Batch 305/938] [D loss: 0.4137] [G loss: 5.3717]\n",
      "[Epoch 1/200] [Batch 306/938] [D loss: 0.4122] [G loss: 5.6171]\n",
      "[Epoch 1/200] [Batch 307/938] [D loss: 0.4148] [G loss: 5.8752]\n",
      "[Epoch 1/200] [Batch 308/938] [D loss: 0.3965] [G loss: 6.1219]\n",
      "[Epoch 1/200] [Batch 309/938] [D loss: 0.4110] [G loss: 6.3616]\n",
      "[Epoch 1/200] [Batch 310/938] [D loss: 0.4173] [G loss: 6.3651]\n",
      "[Epoch 1/200] [Batch 311/938] [D loss: 0.4102] [G loss: 6.2939]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|          | 0/200 [00:05<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/200] [Batch 312/938] [D loss: 0.4187] [G loss: 6.4447]\n",
      "[Epoch 1/200] [Batch 313/938] [D loss: 0.4061] [G loss: 6.8685]\n",
      "[Epoch 1/200] [Batch 314/938] [D loss: 0.4229] [G loss: 6.4205]\n",
      "[Epoch 1/200] [Batch 315/938] [D loss: 0.4093] [G loss: 6.7762]\n",
      "[Epoch 1/200] [Batch 316/938] [D loss: 0.4166] [G loss: 6.5186]\n",
      "[Epoch 1/200] [Batch 317/938] [D loss: 0.4098] [G loss: 6.2701]\n",
      "[Epoch 1/200] [Batch 318/938] [D loss: 0.4011] [G loss: 6.3239]\n",
      "[Epoch 1/200] [Batch 319/938] [D loss: 0.4009] [G loss: 6.4281]\n",
      "[Epoch 1/200] [Batch 320/938] [D loss: 0.3898] [G loss: 7.0541]\n",
      "[Epoch 1/200] [Batch 321/938] [D loss: 0.3781] [G loss: 6.9731]\n",
      "[Epoch 1/200] [Batch 322/938] [D loss: 0.3821] [G loss: 7.0915]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|          | 0/200 [00:05<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/200] [Batch 323/938] [D loss: 0.4033] [G loss: 6.2720]\n",
      "[Epoch 1/200] [Batch 324/938] [D loss: 0.3871] [G loss: 6.3207]\n",
      "[Epoch 1/200] [Batch 325/938] [D loss: 0.4040] [G loss: 5.7459]\n",
      "[Epoch 1/200] [Batch 326/938] [D loss: 0.3882] [G loss: 6.3777]\n",
      "[Epoch 1/200] [Batch 327/938] [D loss: 0.4021] [G loss: 5.7355]\n",
      "[Epoch 1/200] [Batch 328/938] [D loss: 0.3851] [G loss: 6.3501]\n",
      "[Epoch 1/200] [Batch 329/938] [D loss: 0.3844] [G loss: 6.5984]\n",
      "[Epoch 1/200] [Batch 330/938] [D loss: 0.3750] [G loss: 5.8463]\n",
      "[Epoch 1/200] [Batch 331/938] [D loss: 0.3995] [G loss: 5.4027]\n",
      "[Epoch 1/200] [Batch 332/938] [D loss: 0.3881] [G loss: 5.5727]\n",
      "[Epoch 1/200] [Batch 333/938] [D loss: 0.3921] [G loss: 5.5330]\n",
      "[Epoch 1/200] [Batch 334/938] [D loss: 0.3953] [G loss: 5.1819]\n",
      "[Epoch 1/200] [Batch 335/938] [D loss: 0.3997] [G loss: 5.4575]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|          | 0/200 [00:05<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/200] [Batch 336/938] [D loss: 0.3881] [G loss: 5.0928]\n",
      "[Epoch 1/200] [Batch 337/938] [D loss: 0.3932] [G loss: 5.0906]\n",
      "[Epoch 1/200] [Batch 338/938] [D loss: 0.3710] [G loss: 5.2065]\n",
      "[Epoch 1/200] [Batch 339/938] [D loss: 0.4034] [G loss: 5.0062]\n",
      "[Epoch 1/200] [Batch 340/938] [D loss: 0.3886] [G loss: 5.2129]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_68305/3716284062.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONFIG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/work/test.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"mnist_generator.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEFAULT_CONFIG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/test.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(config, dataloader, discriminator, generator, optimizer_G, optimizer_D)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_imgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_labels\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 目标是让生成图片被判为真实\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mg_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0moptimizer_G\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;31m# Save Images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    117\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                    group['eps'])\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "CONFIG = {\n",
    "    'n_epochs': 200,\n",
    "    'batch_size': 64,\n",
    "    'lr': 0.0002,\n",
    "    'latent_dim': 100,\n",
    "    'save_interval': 500,\n",
    "    'g_model_path': '',\n",
    "    'save_path': 'images/task2'\n",
    "}\n",
    "\n",
    "print(1)\n",
    "from test import main\n",
    "\n",
    "main(CONFIG)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-1.8",
   "language": "python",
   "name": "pytorch-1.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
